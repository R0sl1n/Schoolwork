{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdab00b3",
   "metadata": {},
   "source": [
    "# Innlevering 1 - DAT801"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6282d8",
   "metadata": {},
   "source": [
    "1. Her importeres nødvendige biblioteker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47df1fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "#from sklearn.pipeline import Pipeline\n",
    "#from sklearn.model_selection import cross_val_predict, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbf8758",
   "metadata": {},
   "source": [
    "2. Her settes lokal path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77e6868",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_DIR = Path.cwd()\n",
    "DATA = NB_DIR/'data'\n",
    "DATA.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6098b35",
   "metadata": {},
   "source": [
    "3. Her gjøres train- og test.csv om til pandas dataframes. Jeg velger med denne oppgaven å ikke kjøre en train_test_split(som jeg også da ville kjørt som stratified for å få en representativ fordeling mellom splittene), da vi har filene i 2 bestanddeler, selv om jeg da må score mot Kaggle underveis. Jeg synes bare det var enklere å forholde seg til."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bf0b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA/'train.csv')\n",
    "test = pd.read_csv(DATA/'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5eb54e",
   "metadata": {},
   "source": [
    "4. Inspiserer så datasettene. Ser manglende verdier i train, men ikke i test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880fa29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b83e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56d5779",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2115bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb25f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974e037d",
   "metadata": {},
   "source": [
    "5. Kikker på oversikten over høyeste representasjon av labels, samt ser på korrelasjoner mellom features, og mellom features og target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2439c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"target\"].hist() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b7832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = train.corr() #Sjekker korrelasjon mellom features for å eventuelt selektere bort features.\n",
    "corr.style.background_gradient(cmap='coolwarm', axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2f924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = train.corr() #sjekker korrelasjon mellom features og target.\n",
    "print(corr_matrix[\"target\"].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04e1506",
   "metadata": {},
   "source": [
    "6. Om jeg fant høyt korrelerte features ville jeg vurdert å fjerne dem med funksjonen under. I dette tilfellet er korrelasjonene så lave, at jeg fjerner ikke noen, da jeg fikk dårligere score ved å gjøre det.\n",
    "\n",
    "#Denne funksjonen fjerner features med korrelasjon over angitt tersel.\n",
    "\n",
    "def remove_collinear_features(x, threshold):\n",
    "    '''\n",
    "    Objective:\n",
    "        Remove collinear features in a dataframe with a correlation coefficient\n",
    "        greater than the threshold. Removing collinear features can help a model \n",
    "        to generalize and improves the interpretability of the model.\n",
    "\n",
    "    Inputs: \n",
    "        x: features dataframe\n",
    "        threshold: features with correlations greater than this value are removed\n",
    "\n",
    "    Output: \n",
    "        dataframe that contains only the non-highly-collinear features\n",
    "    '''\n",
    "\n",
    "    # Calculate the correlation matrix\n",
    "    corr_matrix = x.corr()\n",
    "    iters = range(len(corr_matrix.columns) - 1)\n",
    "    drop_cols = []\n",
    "\n",
    "    # Iterate through the correlation matrix and compare correlations\n",
    "    for i in iters:\n",
    "        for j in range(i+1):\n",
    "            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n",
    "            col = item.columns\n",
    "            row = item.index\n",
    "            val = abs(item.values)\n",
    "\n",
    "            # If correlation exceeds the threshold\n",
    "            if val >= threshold:\n",
    "                # Print the correlated features and the correlation value\n",
    "                print(col.values[0], \"|\", row.values[0], \"|\", round(val[0][0], 2))\n",
    "                drop_cols.append(col.values[0])\n",
    "\n",
    "    # Drop one of each pair of correlated columns\n",
    "    drops = set(drop_cols)\n",
    "    print(drops)\n",
    "    x = x.drop(columns=drops, inplace=True)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60ed077",
   "metadata": {},
   "source": [
    "6. Her tilegnes features i X_train og id kolonnen blir droppet. Labels/targets lagres i y_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6220765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop([\"id\", \"target\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6bb786",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[\"target\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2e955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop([\"id\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9994d407",
   "metadata": {},
   "source": [
    "7. Her imputeres manglende verdier i datasettet med strategien median verdi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1149703",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(strategy = \"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1166bb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed = imp.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6ff329",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_imputed = imp.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7551e6a0",
   "metadata": {},
   "source": [
    "8. Her skaleres det ferdig imputerte datasettet ved å bruke StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e99bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909e3ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std = std.fit_transform(X_train_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec478e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std = pd.DataFrame(data=X_train_std,columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce21970",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_std = std.transform(X_test_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e73e57",
   "metadata": {},
   "source": [
    "9. Modellvalg - Jeg har valgt å bruke et voting ensemble for å forbedre treffsikkerheten på predikasjoner. Jeg har i andre notebooks testet med å bruke GridSearchCV sammen med RandomForestClassifier, og bruker derfor optimaliserte parametre på denne. Siden dette er ganske tidkrevende, velger jeg å bruke defaultverdier på de andre modellene, med unntak av random_state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10de9da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth = 18, max_features= 5, min_samples_leaf = 3, min_samples_split = 11, n_estimators = 850,\n",
    " n_jobs = -1, random_state = 42)\n",
    "gb = GradientBoostingClassifier(random_state = 42)\n",
    "gbm = xgb.XGBClassifier(n_estimators= 2000, max_depth= 4, min_child_weight= 2, gamma=0.9,\n",
    "subsample=0.8, colsample_bytree=0.8, objective= 'multi:softmax', scale_pos_weight=1, booster = \"dart\", n_jobs = -1)\n",
    "#svc = SVC(random_state = 42, probability=True)\n",
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7393d7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [(\"rf\", rf),\n",
    "         (\"gb\", gb),\n",
    "         (\"gbm\", gbm),\n",
    "         (\"gnb\", gnb)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cb9252",
   "metadata": {},
   "source": [
    "10. Knytter valgte modeller til VotingClassifier og trener modellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c013f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = VotingClassifier(models, voting=\"soft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f716025",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d835a7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_acc = accuracy_score(y_train, ensemble.predict(X_train_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c89aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Train Accuracy: {}'.format(train_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5927f038",
   "metadata": {},
   "source": [
    "11. Predikerer på testsettet basert på den trente modellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a457443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ensemble.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345ea550",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7903541",
   "metadata": {},
   "source": [
    "12. Lager innleveringsfil ved å lage en pandas dataframe med id fra testfilen og predikasjoner fra esemblet, konvertert til en excelfil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031e3327",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'target': y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d88b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c709c5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_lkk_7.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b326447",
   "metadata": {},
   "source": [
    "13. Final notes. Dersom dette hadde blitt levert som 1 datasett(1 fil, og ikke noe Kaggle konkurranse), ville jeg brukt train,test,split på datasettet. Jeg ville da ha rensket i nullverdier/korrelerte features og lignende før jeg hadde splittet opp datasettet. Hadde jeg ikke brukt voting ensemble(dette tok fryktelig lang tid å trene på dette datasettet. Etter den hadde stått i 2 dager avbrøt jeg den. Jeg har tydeligvis vært for detaljert i mine innstillinger på XGboost) ville jeg benyttet RandomSearch + GridSearchCV for å ivareta kryssvalidering og hyperparametertuning. Jeg ville da også hatt muligheten for å score underveis, samt laget en confusion matrix for å se på treffsikkerheten til modellen min med TP, FP, TN, FN. Med tanke på at jeg nå ikke har en y_test tilgjengelig å sammenligne med på måten jeg har løst oppgaven min, så får jeg ikke gjort dette. Hadde jeg hatt bedre tid, ville jeg også ha testet stacking av modeller sammen med en booster og trent modellen på nytt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8a8c57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAT801",
   "language": "python",
   "name": "dat801"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
